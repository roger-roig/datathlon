{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import regression models\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import scaling libraries\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dabase credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = 'mysql+pymysql:'\n",
    "user = 'ironhacker_read'\n",
    "password = 'ir0nhack3r'\n",
    "ip = '35.239.232.23'\n",
    "database = 'cookies'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifiyng numbers of columns displayed \n",
    "pd.set_option('display.max_columns',100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = f'{driver}//{user}:{password}@{ip}/{database}'\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "query = 'SHOW TABLES'\n",
    "\n",
    "user_df = pd.read_sql(query,engine)\n",
    "user_df\n",
    "\n",
    "\n",
    "query2 = \"\"\"\n",
    "SELECT * FROM cookies_quality\n",
    "\"\"\"\n",
    "\n",
    "cookies_df_original = pd.read_sql(query2, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cookies_df = cookies_df_original.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_box_plots(df):\n",
    "    '''\n",
    "    Input: DataFrame\n",
    "    \n",
    "    # Create the boxplots for all the features of our dataset.\n",
    "    '''\n",
    "    cols = list(cookies_df.select_dtypes(include=['int64','float64']).columns)\n",
    "\n",
    "    f, ax = plt.subplots(len(cols)//3,4, figsize=(12,10))\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.4,hspace=0.4)\n",
    "\n",
    "    i = 0\n",
    "    for row in ax:\n",
    "        for col in row:\n",
    "            if i == len(cols): \n",
    "                break\n",
    "            else:    \n",
    "                sns.boxplot(cookies_df[cols[i]], ax=col)\n",
    "                i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df):\n",
    "    '''\n",
    "    Input: DataFrame\n",
    "    Output: DataFrame\n",
    "    \n",
    "    # Change crunch factor type, drop NaN values and drop 3 columns that don't give useful information.\n",
    "    '''\n",
    "    \n",
    "    df['crunch factor'] = df['crunch factor'].astype('float')\n",
    "    df = df.dropna()\n",
    "    df = df.drop(['diameter','aesthetic appeal','id'], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(df):\n",
    "    '''\n",
    "    Input: DataFrame\n",
    "    Outpu: DataFrame\n",
    "    \n",
    "    # One hot encodes categorical features. Drops columns that were encoded and one of the hot encoded\n",
    "    # colums to avoid uniform information.\n",
    "    '''\n",
    "    \n",
    "    flavour_list = ['raisins', 'nuts', 'chocolate', 'oats', 'peanut butter']\n",
    "    \n",
    "    for flavour in flavour_list:\n",
    "        df[flavour] = 0\n",
    "\n",
    "    for flavour in flavour_list:\n",
    "        df[flavour] = np.where(df['mixins'].str.contains(flavour), 1, 0)\n",
    "        \n",
    "    \n",
    "    df['butter_type_int'] = pd.get_dummies(df['butter type'],drop_first=True)\n",
    "    \n",
    "    df = df.drop(['mixins','butter type','raisins'],axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanOutliers(df):\n",
    "    '''\n",
    "    Input: DataFrame\n",
    "    Output: DataFrame\n",
    "    \n",
    "    # Returns a Dataframe without outliers\n",
    "    '''\n",
    "    \n",
    "    cols = ['sugar to flour ratio', 'sugar index', 'bake temp', 'chill time',\n",
    "       'calories', 'density', 'pH', 'grams baking soda', 'bake time',\n",
    "       'quality', 'weight', 'crunch factor']\n",
    "    \n",
    "    for col in cols:\n",
    "        q1 = df[col].quantile(0.25)\n",
    "        q3 = df[col].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        df[col] = df[col].apply(lambda x: x if x > q1 - 3 * iqr and x < q3 + 3 * iqr else np.nan)   \n",
    "        \n",
    "    df = df.dropna()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversion(x):\n",
    "    '''\n",
    "    Input: Series\n",
    "    \n",
    "    # Maps values of a given list, array or Series.\n",
    "    '''\n",
    "    \n",
    "    if x >= 9:\n",
    "        return 2\n",
    "    elif x <= 6:\n",
    "        return 0\n",
    "    else: \n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_quality(df):\n",
    "    '''\n",
    "    Input: DataFrame\n",
    "    \n",
    "    # Maps values of quality Series with the conversion function.\n",
    "    '''\n",
    "    \n",
    "    df['quality_label'] = df['quality'].apply(lambda x: conversion(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_scaling(df):\n",
    "    '''\n",
    "    Input: DataFrame\n",
    "    Output: DataFrame\n",
    "    \n",
    "    # Return a DataFrame without the target and hot encoded columns.\n",
    "    '''\n",
    "    column_list = ['quality','nuts', 'chocolate', 'oats', 'peanut butter','butter_type_int']\n",
    "    \n",
    "    return df.drop(column_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizer(df):\n",
    "    '''\n",
    "    Input: DataFrame\n",
    "    Output: Array\n",
    "    \n",
    "    # Normalize samples individually to unit norm.\n",
    "    '''\n",
    "    df_normal = prepare_for_scaling(df)\n",
    "    transformer = Normalizer().fit(df_normal)\n",
    "    \n",
    "    return transformer.transform(df_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_scaler(df):\n",
    "    '''\n",
    "    Input: DataFrame\n",
    "    Output: Array\n",
    "    \n",
    "    # Scale features using statistics that are robust to outliers.\n",
    "    '''\n",
    "    df_robust = prepare_for_scaling(df)\n",
    "    transformer = RobustScaler().fit(df_robust)\n",
    "    \n",
    "    return transformer.transform(df_robust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler(df):\n",
    "    '''\n",
    "    Input: DataFrame\n",
    "    Output: DataFrame\n",
    "    \n",
    "    # Transforms features by scaling each feature to a given range.\n",
    "    '''\n",
    "    df = prepare_for_scaling(df)\n",
    "    transformer = MinMaxScaler().fit(df)\n",
    "    \n",
    "    return transformer.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scaler(df):\n",
    "    '''\n",
    "    Input: DataFrame\n",
    "    Output: Array\n",
    "    \n",
    "    # Standardize features by removing the mean and scaling to unit variance.\n",
    "    '''\n",
    "    df = prepare_for_scaling(df)\n",
    "    scaler = StandardScaler().fit(df)\n",
    "    \n",
    "    return scaler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_definitive_df(array, df):\n",
    "    '''\n",
    "    Input: Array, DataFrame\n",
    "    Output: DataFrame\n",
    "    \n",
    "    # Converts the normalized/standardized array to a DataFrame and concats the result\n",
    "    # to the one hot encoded and quality columns.\n",
    "    '''\n",
    "    \n",
    "    columns_set = set(df.columns)\n",
    "    column_list = ['quality', 'nuts', 'chocolate', 'oats', 'peanut butter','butter_type_int']\n",
    "    normalized_columns = columns_set.difference(set(column_list))\n",
    "    normalized_df = pd.DataFrame(array, columns=normalized_columns)\n",
    "    concat_df = pd.concat([normalized_df, df[column_list].reset_index(drop=True)], axis=1,ignore_index=False)\n",
    "    \n",
    "    return concat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_model = LinearRegression()\n",
    "knn_model = KNeighborsRegressor()\n",
    "tree_model = DecisionTreeRegressor()\n",
    "forest_model = RandomForestRegressor()\n",
    "svr_model = SVR()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List with the different models that will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [lin_model,knn_model,tree_model,forest_model,svr_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignoring possible errors, when we use cross validation mostly.\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRY NUMBER 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With outliers and scaling = normalizer\n",
    "\n",
    "cookies_df = cookies_df_original.copy()\n",
    "\n",
    "cookies_cleaned = clean_df(cookies_df)\n",
    "cookies_encoded = encode(cookies_cleaned)\n",
    "cookies_normalized = normalizer(cookies_encoded)\n",
    "\n",
    "cookies_concat = create_definitive_df(cookies_normalized,cookies_encoded)\n",
    "X = cookies_concat.drop('quality',axis=1)\n",
    "y = cookies_concat['quality']\n",
    "\n",
    "scores_list_try_1 = []\n",
    "\n",
    "models_names = ['Linear Regression','KNN','DecisionTree','RandomForest','SVR']\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    cv = cross_val_score(models[i],X,y,cv=10,scoring='r2')\n",
    "    scores_list_try_1.append((i,np.mean(cv)))\n",
    "    \n",
    "for i in range(len(scores_list_try_1)):\n",
    "    print(f'{models_names[i]}: {scores_list_try_1[i][1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRY NUMBER 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without outliers and scaling = normalizer\n",
    "\n",
    "cookies_df = cookies_df_original.copy()\n",
    "\n",
    "cookies_cleaned = clean_df(cookies_df)\n",
    "cookies_notOL = cleanOutliers(cookies_cleaned)\n",
    "cookies_encoded = encode(cookies_notOL)\n",
    "cookies_normalized = normalizer(cookies_encoded)\n",
    "\n",
    "cookies_concat = create_definitive_df(cookies_normalized,cookies_encoded)\n",
    "# cookies_concat.dropna(inplace=True)\n",
    "\n",
    "X = cookies_concat.drop('quality',axis=1)\n",
    "y = cookies_concat['quality']\n",
    "\n",
    "scores_list_try_2 = []\n",
    "\n",
    "models_names = ['Linear Regression','KNN','DecisionTree','RandomForest','SVR']\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    cv = cross_val_score(models[i],X,y,cv=10,scoring='r2')\n",
    "    scores_list_try_2.append((i,np.mean(cv)))\n",
    "    \n",
    "for i in range(len(scores_list_try_2)):\n",
    "    print(f'{models_names[i]}: {scores_list_try_2[i][1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRY NUMBER 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Without outliers and scaling = robust\n",
    "\n",
    "cookies_df = cookies_df_original.copy()\n",
    "\n",
    "cookies_cleaned = clean_df(cookies_df)\n",
    "cookies_notOL = cleanOutliers(cookies_cleaned)\n",
    "cookies_encoded = encode(cookies_notOL)\n",
    "cookies_normalized = robust_scaler(cookies_encoded)\n",
    "\n",
    "cookies_concat = create_definitive_df(cookies_normalized,cookies_encoded)\n",
    "# cookies_concat.dropna(inplace=True)\n",
    "\n",
    "X = cookies_concat.drop('quality',axis=1)\n",
    "y = cookies_concat['quality']\n",
    "\n",
    "scores_list_try_3 = []\n",
    "\n",
    "models_names = ['Linear Regression','KNN','DecisionTree','RandomForest','SVR']\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    cv = cross_val_score(models[i],X,y,cv=10,scoring='r2')\n",
    "    scores_list_try_3.append((i,np.mean(cv)))\n",
    "    \n",
    "for i in range(len(scores_list_try_3)):\n",
    "    print(f'{models_names[i]}: {scores_list_try_3[i][1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRY NUMBER 4 (BEST TRY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Without outliers and scaling = minmaxscaler()\n",
    "\n",
    "cookies_df = cookies_df_original.copy()\n",
    "\n",
    "cookies_cleaned = clean_df(cookies_df)\n",
    "cookies_notOL = cleanOutliers(cookies_cleaned)\n",
    "cookies_encoded = encode(cookies_notOL)\n",
    "cookies_normalized = min_max_scaler(cookies_encoded)\n",
    "\n",
    "cookies_concat = create_definitive_df(cookies_normalized,cookies_encoded)\n",
    "\n",
    "X = cookies_concat.drop('quality',axis=1)\n",
    "y = cookies_concat['quality']\n",
    "\n",
    "scores_list_try_4 = []\n",
    "\n",
    "models_names = ['Linear Regression','KNN','DecisionTree','RandomForest','SVR']\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    cv = cross_val_score(models[i],X,y,cv=10,scoring='r2')\n",
    "    scores_list_try_4.append((i,np.mean(cv)))\n",
    "    \n",
    "for i in range(len(scores_list_try_4)):\n",
    "    print(f'{models_names[i]}: {scores_list_try_4[i][1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRY NUMBER 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Without outliers and scaling = minmaxscaler()\n",
    "\n",
    "cookies_df = cookies_df_original.copy()\n",
    "\n",
    "cookies_cleaned = clean_df(cookies_df)\n",
    "cookies_notOL = cleanOutliers(cookies_cleaned)\n",
    "cookies_encoded = encode(cookies_notOL)\n",
    "cookies_normalized = standard_scaler(cookies_encoded)\n",
    "\n",
    "cookies_concat = create_definitive_df(cookies_normalized,cookies_encoded)\n",
    "\n",
    "X = cookies_concat.drop('quality',axis=1)\n",
    "y = cookies_concat['quality']\n",
    "\n",
    "scores_list_try_5 = []\n",
    "\n",
    "models_names = ['Linear Regression','KNN','DecisionTree','RandomForest','SVR']\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    cv = cross_val_score(models[i],X,y,cv=10,scoring='r2')\n",
    "    scores_list_try_5.append((i,np.mean(cv)))\n",
    "    \n",
    "for i in range(len(scores_list_try_5)):\n",
    "    print(f'{models_names[i]}: {scores_list_try_5[i][1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRY NUMBER 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# With outliers and scaling = robust\n",
    "\n",
    "cookies_df = cookies_df_original.copy()\n",
    "\n",
    "cookies_cleaned = clean_df(cookies_df)\n",
    "cookies_encoded = encode(cookies_cleaned)\n",
    "cookies_normalized = robust_scaler(cookies_encoded)\n",
    "\n",
    "cookies_concat = create_definitive_df(cookies_normalized,cookies_encoded)\n",
    "X = cookies_concat.drop('quality',axis=1)\n",
    "y = cookies_concat['quality']\n",
    "\n",
    "scores_list_try_6 = []\n",
    "\n",
    "models_names = ['Linear Regression','KNN','DecisionTree','RandomForest','SVR']\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    cv = cross_val_score(models[i],X,y,cv=10,scoring='r2')\n",
    "    scores_list_try_6.append((i,np.mean(cv)))\n",
    "    \n",
    "for i in range(len(scores_list_try_6)):\n",
    "    print(f'{models_names[i]}: {scores_list_try_6[i][1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRY NUMBER 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With outliers and scaling = standardscaler\n",
    "\n",
    "cookies_df = cookies_df_original.copy()\n",
    "\n",
    "cookies_cleaned = clean_df(cookies_df)\n",
    "cookies_encoded = encode(cookies_cleaned)\n",
    "cookies_normalized = standard_scaler(cookies_encoded)\n",
    "\n",
    "cookies_concat = create_definitive_df(cookies_normalized,cookies_encoded)\n",
    "X = cookies_concat.drop('quality',axis=1)\n",
    "y = cookies_concat['quality']\n",
    "\n",
    "scores_list_try_7 = []\n",
    "\n",
    "models_names = ['Linear Regression','KNN','DecisionTree','RandomForest','SVR']\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    cv = cross_val_score(models[i],X,y,cv=10,scoring='r2')\n",
    "    scores_list_try_7.append((i,np.mean(cv)))\n",
    "    \n",
    "for i in range(len(scores_list_try_7)):\n",
    "    print(f'{models_names[i]}: {scores_list_try_7[i][1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRY NUMBER 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With outliers and scaling = standardscaler\n",
    "\n",
    "cookies_df = cookies_df_original.copy()\n",
    "\n",
    "cookies_cleaned = clean_df(cookies_df)\n",
    "cookies_notOL = cleanOutliers(cookies_cleaned)\n",
    "cookies_encoded = encode(cookies_notOL)\n",
    "cookies_normalized = min_max_scaler(cookies_encoded)\n",
    "\n",
    "cookies_concat_pref = create_definitive_df(cookies_normalized,cookies_encoded)\n",
    "cookies_concat = convert_quality(cookies_concat_pref)\n",
    "\n",
    "X = cookies_concat.drop(['quality','quality_label'],axis=1)\n",
    "y = cookies_concat['quality_label']\n",
    "\n",
    "scores_list_try_8 = []\n",
    "\n",
    "models_names = ['Linear Regression','KNN','DecisionTree','RandomForest','SVR']\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    cv = cross_val_score(models[i],X,y,cv=10,scoring='r2')\n",
    "    scores_list_try_8.append((i,np.mean(cv)))\n",
    "\n",
    "for i in range(len(scores_list_try_8)):\n",
    "    print(f'{models_names[i]}: {scores_list_try_8[i][1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
