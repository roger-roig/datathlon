{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import regression models\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import scaling libraries\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dabase credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = 'mysql+pymysql:'\n",
    "user = 'ironhacker_read'\n",
    "password = 'ir0nhack3r'\n",
    "ip = '35.239.232.23'\n",
    "database = 'cookies'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifiyng numbers of columns displayed \n",
    "pd.set_option('display.max_columns',100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = f'{driver}//{user}:{password}@{ip}/{database}'\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "query = 'SHOW TABLES'\n",
    "\n",
    "user_df = pd.read_sql(query,engine)\n",
    "user_df\n",
    "\n",
    "\n",
    "query2 = \"\"\"\n",
    "SELECT * FROM cookies_quality\n",
    "\"\"\"\n",
    "\n",
    "cookies_df_original = pd.read_sql(query2, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cookies_df = cookies_df_original.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_box_plots(df):\n",
    "    '''\n",
    "    Input: DataFrame\n",
    "    \n",
    "    # Create the boxplots for all the features of our dataset.\n",
    "    '''\n",
    "    cols = list(cookies_df.select_dtypes(include=['int64','float64']).columns)\n",
    "\n",
    "    f, ax = plt.subplots(len(cols)//3,4, figsize=(12,10))\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.4,hspace=0.4)\n",
    "\n",
    "    i = 0\n",
    "    for row in ax:\n",
    "        for col in row:\n",
    "            if i == len(cols): \n",
    "                break\n",
    "            else:    \n",
    "                sns.boxplot(cookies_df[cols[i]], ax=col)\n",
    "                i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df):\n",
    "    '''\n",
    "    Input: DataFrame\n",
    "    Output: DataFrame\n",
    "    \n",
    "    # Change crunch factor type, drop NaN values and drop 3 columns that don't give useful information.\n",
    "    '''\n",
    "    \n",
    "    df['crunch factor'] = df['crunch factor'].astype('float')\n",
    "    df = df.dropna()\n",
    "    df = df.drop(['diameter','aesthetic appeal','id'], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(df):\n",
    "    '''\n",
    "    Input: DataFrame\n",
    "    Outpu: DataFrame\n",
    "    \n",
    "    # One hot encodes categorical features. Drops columns that were encoded and one of the hot encoded\n",
    "    # colums to avoid uniform information.\n",
    "    '''\n",
    "    \n",
    "    flavour_list = ['raisins', 'nuts', 'chocolate', 'oats', 'peanut butter']\n",
    "    \n",
    "    for flavour in flavour_list:\n",
    "        df[flavour] = 0\n",
    "\n",
    "    for flavour in flavour_list:\n",
    "        df[flavour] = np.where(df['mixins'].str.contains(flavour), 1, 0)\n",
    "        \n",
    "    \n",
    "    df['butter_type_int'] = pd.get_dummies(df['butter type'],drop_first=True)\n",
    "    \n",
    "    df = df.drop(['mixins','butter type','raisins'],axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanOutliers(df):\n",
    "    '''\n",
    "    Input: DataFrame\n",
    "    Output: DataFrame\n",
    "    \n",
    "    # Returns a Dataframe without outliers\n",
    "    '''\n",
    "    \n",
    "    cols = ['sugar to flour ratio', 'sugar index', 'bake temp', 'chill time',\n",
    "       'calories', 'density', 'pH', 'grams baking soda', 'bake time',\n",
    "       'quality', 'weight', 'crunch factor']\n",
    "    \n",
    "    for col in cols:\n",
    "        q1 = df[col].quantile(0.25)\n",
    "        q3 = df[col].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        df[col] = df[col].apply(lambda x: x if x > q1 - 3 * iqr and x < q3 + 3 * iqr else np.nan)   \n",
    "        \n",
    "    df = df.dropna()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversion(x):\n",
    "    '''\n",
    "    Input: Series\n",
    "    \n",
    "    # Maps values of a given list, array or Series.\n",
    "    '''\n",
    "    \n",
    "    if x >= 9:\n",
    "        return 2\n",
    "    elif x <= 6:\n",
    "        return 0\n",
    "    else: \n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_quality(df):\n",
    "    '''\n",
    "    Input: DataFrame\n",
    "    \n",
    "    # Maps values of quality Series with the conversion function.\n",
    "    '''\n",
    "    \n",
    "    df['quality_label'] = df['quality'].apply(lambda x: conversion(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_scaling(df):\n",
    "    '''\n",
    "    Input: DataFrame\n",
    "    Output: DataFrame\n",
    "    \n",
    "    # Return a DataFrame without the target and hot encoded columns.\n",
    "    '''\n",
    "    column_list = ['quality','nuts', 'chocolate', 'oats', 'peanut butter','butter_type_int']\n",
    "    \n",
    "    return df.drop(column_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizer(df):\n",
    "    '''\n",
    "    Input: DataFrame\n",
    "    Output: Array\n",
    "    \n",
    "    # Normalize samples individually to unit norm.\n",
    "    '''\n",
    "    df_normal = prepare_for_scaling(df)\n",
    "    transformer = Normalizer().fit(df_normal)\n",
    "    \n",
    "    return transformer.transform(df_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_scaler(df):\n",
    "    '''\n",
    "    Input: DataFrame\n",
    "    Output: Array\n",
    "    \n",
    "    # Scale features using statistics that are robust to outliers.\n",
    "    '''\n",
    "    df_robust = prepare_for_scaling(df)\n",
    "    transformer = RobustScaler().fit(df_robust)\n",
    "    \n",
    "    return transformer.transform(df_robust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler(df):\n",
    "    '''\n",
    "    Input: DataFrame\n",
    "    Output: DataFrame\n",
    "    \n",
    "    # Transforms features by scaling each feature to a given range.\n",
    "    '''\n",
    "    df = prepare_for_scaling(df)\n",
    "    transformer = MinMaxScaler().fit(df)\n",
    "    \n",
    "    return transformer.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scaler(df):\n",
    "    '''\n",
    "    Input: DataFrame\n",
    "    Output: Array\n",
    "    \n",
    "    # Standardize features by removing the mean and scaling to unit variance.\n",
    "    '''\n",
    "    df = prepare_for_scaling(df)\n",
    "    scaler = StandardScaler().fit(df)\n",
    "    \n",
    "    return scaler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_definitive_df(array, df):\n",
    "    '''\n",
    "    Input: Array, DataFrame\n",
    "    Output: DataFrame\n",
    "    \n",
    "    # Converts the normalized/standardized array to a DataFrame and concats the result\n",
    "    # to the one hot encoded and quality columns.\n",
    "    '''\n",
    "    \n",
    "    columns_set = set(df.columns)\n",
    "    column_list = ['quality', 'nuts', 'chocolate', 'oats', 'peanut butter','butter_type_int']\n",
    "    normalized_columns = columns_set.difference(set(column_list))\n",
    "    normalized_df = pd.DataFrame(array, columns=normalized_columns)\n",
    "    concat_df = pd.concat([normalized_df, df[column_list].reset_index(drop=True)], axis=1,ignore_index=False)\n",
    "    \n",
    "    return concat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_model = LinearRegression()\n",
    "knn_model = KNeighborsRegressor()\n",
    "tree_model = DecisionTreeRegressor()\n",
    "forest_model = RandomForestRegressor()\n",
    "svr_model = SVR()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List with the different models that will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [lin_model,knn_model,tree_model,forest_model,svr_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignoring possible errors, when we use cross validation mostly.\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRY NUMBER 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: 0.6335129333289574\n",
      "KNN: 0.6366434279438353\n",
      "DecisionTree: 0.5187033540642194\n",
      "RandomForest: 0.7204303182507275\n",
      "SVR: 0.5783735573233884\n"
     ]
    }
   ],
   "source": [
    "# With outliers and scaling = normalizer\n",
    "\n",
    "cookies_df = cookies_df_original.copy()\n",
    "\n",
    "cookies_cleaned = clean_df(cookies_df)\n",
    "cookies_encoded = encode(cookies_cleaned)\n",
    "cookies_normalized = normalizer(cookies_encoded)\n",
    "\n",
    "cookies_concat = create_definitive_df(cookies_normalized,cookies_encoded)\n",
    "X = cookies_concat.drop('quality',axis=1)\n",
    "y = cookies_concat['quality']\n",
    "\n",
    "scores_list_try_1 = []\n",
    "\n",
    "models_names = ['Linear Regression','KNN','DecisionTree','RandomForest','SVR']\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    cv = cross_val_score(models[i],X,y,cv=10,scoring='r2')\n",
    "    scores_list_try_1.append((i,np.mean(cv)))\n",
    "    \n",
    "for i in range(len(scores_list_try_1)):\n",
    "    print(f'{models_names[i]}: {scores_list_try_1[i][1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRY NUMBER 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: 0.6529612304311\n",
      "KNN: 0.6198366532500843\n",
      "DecisionTree: 0.532324402335155\n",
      "RandomForest: 0.7169196941088928\n",
      "SVR: 0.5556063764934189\n"
     ]
    }
   ],
   "source": [
    "# Without outliers and scaling = normalizer\n",
    "\n",
    "cookies_df = cookies_df_original.copy()\n",
    "\n",
    "cookies_cleaned = clean_df(cookies_df)\n",
    "cookies_notOL = cleanOutliers(cookies_cleaned)\n",
    "cookies_encoded = encode(cookies_notOL)\n",
    "cookies_normalized = normalizer(cookies_encoded)\n",
    "\n",
    "cookies_concat = create_definitive_df(cookies_normalized,cookies_encoded)\n",
    "# cookies_concat.dropna(inplace=True)\n",
    "\n",
    "X = cookies_concat.drop('quality',axis=1)\n",
    "y = cookies_concat['quality']\n",
    "\n",
    "scores_list_try_2 = []\n",
    "\n",
    "models_names = ['Linear Regression','KNN','DecisionTree','RandomForest','SVR']\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    cv = cross_val_score(models[i],X,y,cv=10,scoring='r2')\n",
    "    scores_list_try_2.append((i,np.mean(cv)))\n",
    "    \n",
    "for i in range(len(scores_list_try_2)):\n",
    "    print(f'{models_names[i]}: {scores_list_try_2[i][1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRY NUMBER 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: 0.6637698413181574\n",
      "KNN: 0.6774788969734425\n",
      "DecisionTree: 0.5544243306946776\n",
      "RandomForest: 0.7411399653731918\n",
      "SVR: 0.7054696384586268\n"
     ]
    }
   ],
   "source": [
    "# Without outliers and scaling = robust\n",
    "\n",
    "cookies_df = cookies_df_original.copy()\n",
    "\n",
    "cookies_cleaned = clean_df(cookies_df)\n",
    "cookies_notOL = cleanOutliers(cookies_cleaned)\n",
    "cookies_encoded = encode(cookies_notOL)\n",
    "cookies_normalized = robust_scaler(cookies_encoded)\n",
    "\n",
    "cookies_concat = create_definitive_df(cookies_normalized,cookies_encoded)\n",
    "# cookies_concat.dropna(inplace=True)\n",
    "\n",
    "X = cookies_concat.drop('quality',axis=1)\n",
    "y = cookies_concat['quality']\n",
    "\n",
    "scores_list_try_3 = []\n",
    "\n",
    "models_names = ['Linear Regression','KNN','DecisionTree','RandomForest','SVR']\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    cv = cross_val_score(models[i],X,y,cv=10,scoring='r2')\n",
    "    scores_list_try_3.append((i,np.mean(cv)))\n",
    "    \n",
    "for i in range(len(scores_list_try_3)):\n",
    "    print(f'{models_names[i]}: {scores_list_try_3[i][1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRY NUMBER 4 (BEST TRY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: 0.6637698413181576\n",
      "KNN: 0.6581967184191442\n",
      "DecisionTree: 0.5549282086490248\n",
      "RandomForest: 0.740697233870638\n",
      "SVR: 0.6746884063377131\n"
     ]
    }
   ],
   "source": [
    "# Without outliers and scaling = minmaxscaler()\n",
    "\n",
    "cookies_df = cookies_df_original.copy()\n",
    "\n",
    "cookies_cleaned = clean_df(cookies_df)\n",
    "cookies_notOL = cleanOutliers(cookies_cleaned)\n",
    "cookies_encoded = encode(cookies_notOL)\n",
    "cookies_normalized = min_max_scaler(cookies_encoded)\n",
    "\n",
    "cookies_concat = create_definitive_df(cookies_normalized,cookies_encoded)\n",
    "\n",
    "X = cookies_concat.drop('quality',axis=1)\n",
    "y = cookies_concat['quality']\n",
    "\n",
    "scores_list_try_4 = []\n",
    "\n",
    "models_names = ['Linear Regression','KNN','DecisionTree','RandomForest','SVR']\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    cv = cross_val_score(models[i],X,y,cv=10,scoring='r2')\n",
    "    scores_list_try_4.append((i,np.mean(cv)))\n",
    "    \n",
    "for i in range(len(scores_list_try_4)):\n",
    "    print(f'{models_names[i]}: {scores_list_try_4[i][1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRY NUMBER 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: 0.6637698413181575\n",
      "KNN: 0.6692749707446497\n",
      "DecisionTree: 0.5589976526883833\n",
      "RandomForest: 0.7385827517663344\n",
      "SVR: 0.7076840695098625\n"
     ]
    }
   ],
   "source": [
    "# Without outliers and scaling = minmaxscaler()\n",
    "\n",
    "cookies_df = cookies_df_original.copy()\n",
    "\n",
    "cookies_cleaned = clean_df(cookies_df)\n",
    "cookies_notOL = cleanOutliers(cookies_cleaned)\n",
    "cookies_encoded = encode(cookies_notOL)\n",
    "cookies_normalized = standard_scaler(cookies_encoded)\n",
    "\n",
    "cookies_concat = create_definitive_df(cookies_normalized,cookies_encoded)\n",
    "\n",
    "X = cookies_concat.drop('quality',axis=1)\n",
    "y = cookies_concat['quality']\n",
    "\n",
    "scores_list_try_5 = []\n",
    "\n",
    "models_names = ['Linear Regression','KNN','DecisionTree','RandomForest','SVR']\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    cv = cross_val_score(models[i],X,y,cv=10,scoring='r2')\n",
    "    scores_list_try_5.append((i,np.mean(cv)))\n",
    "    \n",
    "for i in range(len(scores_list_try_5)):\n",
    "    print(f'{models_names[i]}: {scores_list_try_5[i][1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRY NUMBER 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: -1.72786555751775\n",
      "KNN: 0.6847597051630185\n",
      "DecisionTree: 0.5558962960421855\n",
      "RandomForest: 0.7426520853459688\n",
      "SVR: 0.7151496303787646\n"
     ]
    }
   ],
   "source": [
    "# With outliers and scaling = robust\n",
    "\n",
    "cookies_df = cookies_df_original.copy()\n",
    "\n",
    "cookies_cleaned = clean_df(cookies_df)\n",
    "cookies_encoded = encode(cookies_cleaned)\n",
    "cookies_normalized = robust_scaler(cookies_encoded)\n",
    "\n",
    "cookies_concat = create_definitive_df(cookies_normalized,cookies_encoded)\n",
    "X = cookies_concat.drop('quality',axis=1)\n",
    "y = cookies_concat['quality']\n",
    "\n",
    "scores_list_try_6 = []\n",
    "\n",
    "models_names = ['Linear Regression','KNN','DecisionTree','RandomForest','SVR']\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    cv = cross_val_score(models[i],X,y,cv=10,scoring='r2')\n",
    "    scores_list_try_6.append((i,np.mean(cv)))\n",
    "    \n",
    "for i in range(len(scores_list_try_6)):\n",
    "    print(f'{models_names[i]}: {scores_list_try_6[i][1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRY NUMBER 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: -1.7278655575177513\n",
      "KNN: 0.6701815517499424\n",
      "DecisionTree: 0.5557551033631674\n",
      "RandomForest: 0.7429795972250524\n",
      "SVR: 0.7135625789010606\n"
     ]
    }
   ],
   "source": [
    "# With outliers and scaling = standardscaler\n",
    "\n",
    "cookies_df = cookies_df_original.copy()\n",
    "\n",
    "cookies_cleaned = clean_df(cookies_df)\n",
    "cookies_encoded = encode(cookies_cleaned)\n",
    "cookies_normalized = standard_scaler(cookies_encoded)\n",
    "\n",
    "cookies_concat = create_definitive_df(cookies_normalized,cookies_encoded)\n",
    "X = cookies_concat.drop('quality',axis=1)\n",
    "y = cookies_concat['quality']\n",
    "\n",
    "scores_list_try_7 = []\n",
    "\n",
    "models_names = ['Linear Regression','KNN','DecisionTree','RandomForest','SVR']\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    cv = cross_val_score(models[i],X,y,cv=10,scoring='r2')\n",
    "    scores_list_try_7.append((i,np.mean(cv)))\n",
    "    \n",
    "for i in range(len(scores_list_try_7)):\n",
    "    print(f'{models_names[i]}: {scores_list_try_7[i][1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRY NUMBER 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'drop'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-fb2c3fb1605c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mcookies_concat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_quality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcookies_concat_pref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcookies_concat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'quality'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'quality_label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcookies_concat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'quality_label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'drop'"
     ]
    }
   ],
   "source": [
    "# With outliers and scaling = standardscaler\n",
    "\n",
    "cookies_df = cookies_df_original.copy()\n",
    "\n",
    "cookies_cleaned = clean_df(cookies_df)\n",
    "cookies_notOL = cleanOutliers(cookies_cleaned)\n",
    "cookies_encoded = encode(cookies_notOL)\n",
    "cookies_normalized = min_max_scaler(cookies_encoded)\n",
    "\n",
    "cookies_concat_pref = create_definitive_df(cookies_normalized,cookies_encoded)\n",
    "cookies_concat = convert_quality(cookies_concat_pref)\n",
    "\n",
    "X = cookies_concat.drop(['quality','quality_label'],axis=1)\n",
    "y = cookies_concat['quality_label']\n",
    "\n",
    "scores_list_try_8 = []\n",
    "\n",
    "models_names = ['Linear Regression','KNN','DecisionTree','RandomForest','SVR']\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    cv = cross_val_score(models[i],X,y,cv=10,scoring='r2')\n",
    "    scores_list_try_8.append((i,np.mean(cv)))\n",
    "\n",
    "for i in range(len(scores_list_try_8)):\n",
    "    print(f'{models_names[i]}: {scores_list_try_8[i][1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_test = \"\"\"\n",
    "SELECT * FROM cookies_evaluate\n",
    "\"\"\"\n",
    "\n",
    "cookies_df_test = pd.read_sql(query_test, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sugar to flour ratio</th>\n",
       "      <th>sugar index</th>\n",
       "      <th>bake temp</th>\n",
       "      <th>chill time</th>\n",
       "      <th>calories</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>grams baking soda</th>\n",
       "      <th>bake time</th>\n",
       "      <th>quality</th>\n",
       "      <th>butter type</th>\n",
       "      <th>weight</th>\n",
       "      <th>diameter</th>\n",
       "      <th>mixins</th>\n",
       "      <th>crunch factor</th>\n",
       "      <th>aesthetic appeal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>520</td>\n",
       "      <td>35.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>0.9930</td>\n",
       "      <td>8.45</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>melted</td>\n",
       "      <td>13.8</td>\n",
       "      <td>7</td>\n",
       "      <td>chocolate</td>\n",
       "      <td>1.43</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.39</td>\n",
       "      <td>10.4</td>\n",
       "      <td>440</td>\n",
       "      <td>20.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0.9974</td>\n",
       "      <td>8.20</td>\n",
       "      <td>0.53</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>melted</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7</td>\n",
       "      <td>chocolate</td>\n",
       "      <td>1.57</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.1</td>\n",
       "      <td>570</td>\n",
       "      <td>21.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.9910</td>\n",
       "      <td>8.32</td>\n",
       "      <td>0.46</td>\n",
       "      <td>10.9</td>\n",
       "      <td>0</td>\n",
       "      <td>melted</td>\n",
       "      <td>12.4</td>\n",
       "      <td>7</td>\n",
       "      <td>chocolate, oats</td>\n",
       "      <td>1.44</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.37</td>\n",
       "      <td>13.5</td>\n",
       "      <td>600</td>\n",
       "      <td>52.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.9975</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.44</td>\n",
       "      <td>9.1</td>\n",
       "      <td>0</td>\n",
       "      <td>melted</td>\n",
       "      <td>14.8</td>\n",
       "      <td>7</td>\n",
       "      <td>chocolate</td>\n",
       "      <td>1.51</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.31</td>\n",
       "      <td>5.5</td>\n",
       "      <td>480</td>\n",
       "      <td>42.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>8.19</td>\n",
       "      <td>0.66</td>\n",
       "      <td>9.3</td>\n",
       "      <td>0</td>\n",
       "      <td>melted</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "      <td>raisins</td>\n",
       "      <td>1.86</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  sugar to flour ratio  sugar index  bake temp  chill time  calories  \\\n",
       "0   1                  0.35          1.0        520        35.0     146.0   \n",
       "1   2                  0.39         10.4        440        20.0     142.0   \n",
       "2   3                  0.33          1.1        570        21.0      82.0   \n",
       "3   4                  0.37         13.5        600        52.0     192.0   \n",
       "4   5                  0.31          5.5        480        42.0     173.0   \n",
       "\n",
       "   density    pH  grams baking soda  bake time  quality butter type  weight  \\\n",
       "0   0.9930  8.45               0.44       10.0        0      melted    13.8   \n",
       "1   0.9974  8.20               0.53       10.0        0      melted    17.0   \n",
       "2   0.9910  8.32               0.46       10.9        0      melted    12.4   \n",
       "3   0.9975  8.00               0.44        9.1        0      melted    14.8   \n",
       "4   0.9951  8.19               0.66        9.3        0      melted    12.8   \n",
       "\n",
       "   diameter           mixins crunch factor  aesthetic appeal  \n",
       "0         7        chocolate          1.43                 3  \n",
       "1         7        chocolate          1.57                 3  \n",
       "2         7  chocolate, oats          1.44                 3  \n",
       "3         7        chocolate          1.51                 3  \n",
       "4         7          raisins          1.86                 3  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cookies_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean train data set\n",
    "\n",
    "cookies_df = cookies_df_original.copy()\n",
    "\n",
    "cookies_cleaned = clean_df(cookies_df)\n",
    "cookies_notOL = cleanOutliers(cookies_cleaned)\n",
    "cookies_encoded = encode(cookies_notOL)\n",
    "cookies_normalized = min_max_scaler(cookies_encoded)\n",
    "\n",
    "cookies_concat = create_definitive_df(cookies_normalized,cookies_encoded)\n",
    "\n",
    "X_train = cookies_concat.drop('quality',axis=1)\n",
    "y_train = cookies_concat['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean test data set\n",
    "\n",
    "cookies_df = cookies_df_test.copy()\n",
    "\n",
    "cookies_cleaned = clean_df(cookies_df)\n",
    "cookies_encoded = encode(cookies_cleaned)\n",
    "cookies_normalized = min_max_scaler(cookies_encoded)\n",
    "\n",
    "cookies_concat = create_definitive_df(cookies_normalized,cookies_encoded)\n",
    "\n",
    "X_test = cookies_concat.drop('quality',axis=1)\n",
    "y_test = cookies_concat['quality']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cookies_concat['predictions'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chill time</th>\n",
       "      <th>weight</th>\n",
       "      <th>sugar index</th>\n",
       "      <th>crunch factor</th>\n",
       "      <th>calories</th>\n",
       "      <th>bake time</th>\n",
       "      <th>bake temp</th>\n",
       "      <th>density</th>\n",
       "      <th>grams baking soda</th>\n",
       "      <th>pH</th>\n",
       "      <th>sugar to flour ratio</th>\n",
       "      <th>quality</th>\n",
       "      <th>nuts</th>\n",
       "      <th>chocolate</th>\n",
       "      <th>oats</th>\n",
       "      <th>peanut butter</th>\n",
       "      <th>butter_type_int</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.006135</td>\n",
       "      <td>0.198020</td>\n",
       "      <td>0.114983</td>\n",
       "      <td>0.319444</td>\n",
       "      <td>0.107531</td>\n",
       "      <td>0.680412</td>\n",
       "      <td>0.221053</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.241758</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.150307</td>\n",
       "      <td>0.158416</td>\n",
       "      <td>0.062718</td>\n",
       "      <td>0.310185</td>\n",
       "      <td>0.192935</td>\n",
       "      <td>0.422680</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.417582</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.007669</td>\n",
       "      <td>0.222772</td>\n",
       "      <td>0.066202</td>\n",
       "      <td>0.171296</td>\n",
       "      <td>0.068711</td>\n",
       "      <td>0.546392</td>\n",
       "      <td>0.242105</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.164835</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.197853</td>\n",
       "      <td>0.237624</td>\n",
       "      <td>0.174216</td>\n",
       "      <td>0.425926</td>\n",
       "      <td>0.194876</td>\n",
       "      <td>0.216495</td>\n",
       "      <td>0.221053</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.296703</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.075153</td>\n",
       "      <td>0.178218</td>\n",
       "      <td>0.139373</td>\n",
       "      <td>0.381944</td>\n",
       "      <td>0.148292</td>\n",
       "      <td>0.412371</td>\n",
       "      <td>0.452632</td>\n",
       "      <td>0.140351</td>\n",
       "      <td>0.186813</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chill time    weight  sugar index  crunch factor  calories  bake time  \\\n",
       "0        0.35  0.006135     0.198020       0.114983  0.319444   0.107531   \n",
       "1        0.39  0.150307     0.158416       0.062718  0.310185   0.192935   \n",
       "2        0.33  0.007669     0.222772       0.066202  0.171296   0.068711   \n",
       "3        0.37  0.197853     0.237624       0.174216  0.425926   0.194876   \n",
       "4        0.31  0.075153     0.178218       0.139373  0.381944   0.148292   \n",
       "\n",
       "   bake temp   density  grams baking soda        pH  sugar to flour ratio  \\\n",
       "0   0.680412  0.221053           0.263158  0.241758                  0.43   \n",
       "1   0.422680  0.315789           0.263158  0.417582                  0.57   \n",
       "2   0.546392  0.242105           0.421053  0.164835                  0.44   \n",
       "3   0.216495  0.221053           0.105263  0.296703                  0.51   \n",
       "4   0.412371  0.452632           0.140351  0.186813                  0.86   \n",
       "\n",
       "   quality  nuts  chocolate  oats  peanut butter  butter_type_int  predictions  \n",
       "0        0     0          1     0              0                1          7.7  \n",
       "1        0     0          1     0              0                1          7.8  \n",
       "2        0     0          1     1              0                1          7.3  \n",
       "3        0     0          1     0              0                1          7.6  \n",
       "4        0     0          0     0              0                1          7.7  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cookies_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cookies_concat.to_csv('cookies_prediction_gameofcookies.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
