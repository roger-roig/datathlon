{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dabase credentials\n",
    "\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "driver = 'mysql+pymysql:'\n",
    "user = 'ironhacker_read'\n",
    "password = 'ir0nhack3r'\n",
    "ip = '35.239.232.23'\n",
    "database = 'cookies'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe\n",
    "\n",
    "connection_string = f'{driver}//{user}:{password}@{ip}/{database}'\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "query = 'SHOW TABLES'\n",
    "\n",
    "user_df = pd.read_sql(query,engine)\n",
    "user_df\n",
    "\n",
    "\n",
    "query2 = \"\"\"\n",
    "SELECT * FROM cookies_quality\n",
    "\"\"\"\n",
    "\n",
    "cookies_df_original = pd.read_sql(query2, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "cookies_df = cookies_df_original.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_box_plots(df):\n",
    "    \n",
    "    cols = list(cookies_df.select_dtypes(include=['int64','float64']).columns)\n",
    "\n",
    "    f, ax = plt.subplots(len(cols)//3,4, figsize=(12,10))\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.4,hspace=0.4)\n",
    "\n",
    "    i = 0\n",
    "    for row in ax:\n",
    "        for col in row:\n",
    "            if i == len(cols): \n",
    "                break\n",
    "            else:    \n",
    "                sns.boxplot(cookies_df[cols[i]], ax=col)\n",
    "                i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df):\n",
    "    '''First cleaning of DataFrame'''\n",
    "    \n",
    "    df['crunch factor'] = df['crunch factor'].astype('float')\n",
    "    df = df.dropna()\n",
    "    df = df.drop(['diameter','aesthetic appeal','id'], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(df):\n",
    "    '''Encodes categorical features'''\n",
    "        \n",
    "    flavour_list = ['raisins', 'nuts', 'chocolate', 'oats', 'peanut butter']\n",
    "    \n",
    "    for flavour in flavour_list:\n",
    "        df[flavour] = 0\n",
    "\n",
    "    for flavour in flavour_list:\n",
    "        df[flavour] = np.where(df['mixins'].str.contains(flavour), 1, 0)\n",
    "        \n",
    "    \n",
    "    df['butter_type_int'] = pd.get_dummies(df['butter type'],drop_first=True)\n",
    "    \n",
    "    df = df.drop(['mixins','butter type','raisins'],axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanOutliers(df):\n",
    "    '''Returns a Dataframe without outliers'''\n",
    "    \n",
    "    cols = ['sugar to flour ratio', 'sugar index', 'bake temp', 'chill time',\n",
    "       'calories', 'density', 'pH', 'grams baking soda', 'bake time',\n",
    "       'quality', 'weight', 'crunch factor']\n",
    "    \n",
    "    for col in cols:\n",
    "        q1 = df[col].quantile(0.25)\n",
    "        q3 = df[col].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        df[col] = df[col].apply(lambda x: x if x > q1 - 3 * iqr and x < q3 + 3 * iqr else np.nan)   \n",
    "        \n",
    "    df = df.dropna()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversion(x):\n",
    "    '''Function to convert quality target to category'''\n",
    "    \n",
    "    if x >= 9:\n",
    "        return 2\n",
    "    elif x <= 6:\n",
    "        return 0\n",
    "    else: \n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_quality(df):\n",
    "    '''Create new categorical quality target'''\n",
    "    \n",
    "    df['quality_label'] = df['quality'].apply(lambda x: conversion(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import regression models\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_scaling(df):\n",
    "    column_list = ['quality','nuts', 'chocolate', 'oats', 'peanut butter','butter_type_int']\n",
    "    return df.drop(column_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizer(df):\n",
    "    df_normal = prepare_for_scaling(df)\n",
    "    transformer = Normalizer().fit(df_normal) # fit does nothing.\n",
    "    return transformer.transform(df_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_scaler(df):\n",
    "    df_robust = prepare_for_scaling(df)\n",
    "    transformer = RobustScaler().fit(df_robust)\n",
    "    return transformer.transform(df_robust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaler(df):\n",
    "    df = prepare_for_scaling(df)\n",
    "    transformer = MinMaxScaler().fit(df)\n",
    "    return transformer.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scaler(df):\n",
    "    df = prepare_for_scaling(df)\n",
    "    scaler = StandardScaler().fit(df)\n",
    "    return scaler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_definitive_df(array, df):\n",
    "    columns_set = set(df.columns)\n",
    "    column_list = ['quality', 'nuts', 'chocolate', 'oats', 'peanut butter','butter_type_int']\n",
    "    normalized_columns = columns_set.difference(set(column_list))\n",
    "    normalized_df = pd.DataFrame(array, columns=normalized_columns)\n",
    "    concat_df = pd.concat([normalized_df, df[column_list].reset_index(drop=True)], axis=1,ignore_index=False)\n",
    "    return concat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_model = LinearRegression()\n",
    "knn_model = KNeighborsRegressor()\n",
    "tree_model = DecisionTreeRegressor()\n",
    "forest_model = RandomForestRegressor()\n",
    "svr_model = SVR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [lin_model,knn_model,tree_model,forest_model,svr_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.6507115819768131\n",
      "Best parameters: {'max_depth': 5, 'max_features': 4}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Parameters to try\n",
    "parameter_grid = {'max_depth': [1, 2, 3, 4, 5],\n",
    "                  'max_features': [1, 2, 3, 4]}\n",
    "\n",
    "# Instantiate stratified cross validation\n",
    "cross_validation = StratifiedKFold(n_splits=10)\n",
    "\n",
    "# Create grid search object on decision tree using stratified cross validation\n",
    "grid_search = GridSearchCV(forest_model,\n",
    "                           param_grid=parameter_grid,\n",
    "                           cv=cross_validation)\n",
    "\n",
    "# Fit model with grid_search\n",
    "grid_search.fit(X, y)\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRY NUMBER 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: 0.6335077371507825\n",
      "KNN: 0.636726043535897\n",
      "DecisionTree: 0.5369759808036288\n",
      "RandomForest: 0.7228831493738137\n",
      "SVR: 0.5783946808893693\n"
     ]
    }
   ],
   "source": [
    "# With outliers and scaling = normalizer\n",
    "\n",
    "cookies_df = cookies_df_original.copy()\n",
    "\n",
    "cookies_cleaned = clean_df(cookies_df)\n",
    "cookies_encoded = encode(cookies_cleaned)\n",
    "cookies_normalized = normalizer(cookies_encoded)\n",
    "\n",
    "cookies_concat = create_definitive_df(cookies_normalized,cookies_encoded)\n",
    "X = cookies_concat.drop('quality',axis=1)\n",
    "y = cookies_concat['quality']\n",
    "\n",
    "scores_list_try_1 = []\n",
    "\n",
    "models_names = ['Linear Regression','KNN','DecisionTree','RandomForest','SVR']\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    cv = cross_val_score(models[i],X,y,cv=10,scoring='r2')\n",
    "    scores_list_try_1.append((i,np.mean(cv)))\n",
    "    \n",
    "for i in range(len(scores_list_try_1)):\n",
    "    print(f'{models_names[i]}: {scores_list_try_1[i][1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRY NUMBER 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: 0.6529285617343934\n",
      "KNN: 0.6197636572312084\n",
      "DecisionTree: 0.5356228020742833\n",
      "RandomForest: 0.7194131725221318\n",
      "SVR: 0.5555830601238809\n"
     ]
    }
   ],
   "source": [
    "# Without outliers and scaling = normalizer\n",
    "\n",
    "cookies_df = cookies_df_original.copy()\n",
    "\n",
    "cookies_cleaned = clean_df(cookies_df)\n",
    "cookies_notOL = cleanOutliers(cookies_cleaned)\n",
    "cookies_encoded = encode(cookies_notOL)\n",
    "cookies_normalized = normalizer(cookies_encoded)\n",
    "\n",
    "cookies_concat = create_definitive_df(cookies_normalized,cookies_encoded)\n",
    "# cookies_concat.dropna(inplace=True)\n",
    "\n",
    "X = cookies_concat.drop('quality',axis=1)\n",
    "y = cookies_concat['quality']\n",
    "\n",
    "scores_list_try_2 = []\n",
    "\n",
    "models_names = ['Linear Regression','KNN','DecisionTree','RandomForest','SVR']\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    cv = cross_val_score(models[i],X,y,cv=10,scoring='r2')\n",
    "    scores_list_try_2.append((i,np.mean(cv)))\n",
    "    \n",
    "for i in range(len(scores_list_try_2)):\n",
    "    print(f'{models_names[i]}: {scores_list_try_2[i][1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRY NUMBER 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: 0.6637252256199793\n",
      "KNN: 0.677266778866967\n",
      "DecisionTree: 0.558288539229331\n",
      "RandomForest: 0.7410952939496223\n",
      "SVR: 0.7053956141360717\n"
     ]
    }
   ],
   "source": [
    "# Without outliers and scaling = robust\n",
    "\n",
    "cookies_df = cookies_df_original.copy()\n",
    "\n",
    "cookies_cleaned = clean_df(cookies_df)\n",
    "cookies_notOL = cleanOutliers(cookies_cleaned)\n",
    "cookies_encoded = encode(cookies_notOL)\n",
    "cookies_normalized = robust_scaler(cookies_encoded)\n",
    "\n",
    "cookies_concat = create_definitive_df(cookies_normalized,cookies_encoded)\n",
    "# cookies_concat.dropna(inplace=True)\n",
    "\n",
    "X = cookies_concat.drop('quality',axis=1)\n",
    "y = cookies_concat['quality']\n",
    "\n",
    "scores_list_try_3 = []\n",
    "\n",
    "models_names = ['Linear Regression','KNN','DecisionTree','RandomForest','SVR']\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    cv = cross_val_score(models[i],X,y,cv=10,scoring='r2')\n",
    "    scores_list_try_3.append((i,np.mean(cv)))\n",
    "    \n",
    "for i in range(len(scores_list_try_3)):\n",
    "    print(f'{models_names[i]}: {scores_list_try_3[i][1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRY NUMBER 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: 0.6637252256199795\n",
      "KNN: 0.6582225567103663\n",
      "DecisionTree: 0.5525740749009879\n",
      "RandomForest: 0.7441172725837208\n",
      "SVR: 0.6746629267940587\n"
     ]
    }
   ],
   "source": [
    "# Without outliers and scaling = minmaxscaler()\n",
    "\n",
    "cookies_df = cookies_df_original.copy()\n",
    "\n",
    "cookies_cleaned = clean_df(cookies_df)\n",
    "cookies_notOL = cleanOutliers(cookies_cleaned)\n",
    "cookies_encoded = encode(cookies_notOL)\n",
    "cookies_normalized = min_max_scaler(cookies_encoded)\n",
    "\n",
    "cookies_concat = create_definitive_df(cookies_normalized,cookies_encoded)\n",
    "\n",
    "X = cookies_concat.drop('quality',axis=1)\n",
    "y = cookies_concat['quality']\n",
    "\n",
    "scores_list_try_4 = []\n",
    "\n",
    "models_names = ['Linear Regression','KNN','DecisionTree','RandomForest','SVR']\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    cv = cross_val_score(models[i],X,y,cv=10,scoring='r2')\n",
    "    scores_list_try_4.append((i,np.mean(cv)))\n",
    "    \n",
    "for i in range(len(scores_list_try_4)):\n",
    "    print(f'{models_names[i]}: {scores_list_try_4[i][1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRY NUMBER 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: 0.6637252256199793\n",
      "KNN: 0.6693200768337431\n",
      "DecisionTree: 0.5585071842092668\n",
      "RandomForest: 0.717415692935818\n",
      "SVR: 0.7077009882157587\n"
     ]
    }
   ],
   "source": [
    "# Without outliers and scaling = minmaxscaler()\n",
    "\n",
    "cookies_df = cookies_df_original.copy()\n",
    "\n",
    "cookies_cleaned = clean_df(cookies_df)\n",
    "cookies_notOL = cleanOutliers(cookies_cleaned)\n",
    "cookies_encoded = encode(cookies_notOL)\n",
    "cookies_normalized = standard_scaler(cookies_encoded)\n",
    "\n",
    "cookies_concat = create_definitive_df(cookies_normalized,cookies_encoded)\n",
    "\n",
    "X = cookies_concat.drop('quality',axis=1)\n",
    "y = cookies_concat['quality']\n",
    "\n",
    "scores_list_try_5 = []\n",
    "\n",
    "models_names = ['Linear Regression','KNN','DecisionTree','RandomForest','SVR']\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    cv = cross_val_score(models[i],X,y,cv=10,scoring='r2')\n",
    "    scores_list_try_5.append((i,np.mean(cv)))\n",
    "    \n",
    "for i in range(len(scores_list_try_5)):\n",
    "    print(f'{models_names[i]}: {scores_list_try_5[i][1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
